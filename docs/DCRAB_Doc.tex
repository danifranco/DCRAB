\documentclass[10pt,a4paper]{report}
\usepackage[margin=1.25in]{geometry}
\usepackage{fancyhdr}
\usepackage[pdftex]{graphicx}
\usepackage{subfigure}
\usepackage{titlesec}
\usepackage{placeins}
\usepackage{color}
\usepackage{verbatim}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{pgf}
\usepackage{float}
\usepackage{hyperref}
\usepackage{multicol}
\usepackage{comment}

\usepackage{lipsum}
\usepackage{microtype}
\usepackage{vwcol}

\setlength{\columnseprule}{1pt}
\def\columnseprulecolor{\color{black!0}}

\usetikzlibrary{arrows,shapes,positioning,shadows,trees,automata}

\tikzset{
  basic/.style  = {draw, text width=2cm, drop shadow, font=\sffamily, rectangle},
  root/.style   = {basic, rounded corners=2pt, thin, align=center,
                   fill=green!30},
  level 2/.style = {basic, rounded corners=6pt, thin,align=center, fill=orange!30,
                   text width=10em},
  level 3/.style = {basic, thin, align=left, fill=pink!60, text width=12em, align=center},
	level 4/.style = {basic, thin, align=left, fill=pink!60, text width=14.5em, align=center},
	level 5/.style = {basic, thin, align=left, fill=pink!60, text width=6.5em, align=center}
}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    filecolor=black,
    urlcolor=blue
}

\author{CC-Staff}
\title{User Documentation}
\date{8 May 2018}

\makeatletter
\let\thetitle\@title
\let\theauthor\@author
\let\thedate\@date
\makeatother

\pagestyle{fancy}
\fancyhf{}
\rhead{\theauthor}
\lhead{DCRAB User Guide}
\cfoot{\thepage}

\titleformat{\chapter}
  {\normalfont\LARGE\bfseries}{\thechapter}{1em}{}
\titlespacing*{\chapter}{0pt}{3.5ex plus 1ex minus .2ex}{2.3ex plus .2ex}


\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{titlepage}
	\centering
    \vspace*{3 cm}
    \includegraphics[scale = 0.6]{../auxFiles/logos/DCRAB_logo.png}\\[1.0 cm]
		\vspace*{2 cm}
	\rule{\linewidth}{0.2 mm} \\[0.4 cm]
	{ \huge \bfseries \thetitle}\\
	\rule{\linewidth}{0.2 mm} \\[0.4 cm]
\vspace*{4.5 cm}
	\begin{minipage}{0.4\textwidth}
		\begin{flushleft} \large
			Document Revision 1.0.1\\
			29 May 2018\\
			\end{flushleft}
			\end{minipage}
			\begin{minipage}{0.4 \textwidth}
			\begin{flushright} \large
			DCRAB v2.0\\
		\end{flushright}
	\end{minipage}\\[2 cm]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\thispagestyle{empty}
\begin{flushleft}
CC-Staff \\
Contact: http://dipc.ehu.es/cc/computing\_resources/staff.html \\
High Performance Computing \\
Donostia International Physics Center, Computing Center \\
Donostia - San Sebasti\'an \\
\vspace{1cm}
DCRAB Copyright (C) 2018 CC-Staff
\end{flushleft}

\newpage
\end{titlepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}

DCRAB is a tool to monitor resource utilization in HPC environments. It works side-by-side with the job scheduler to collect runtime information about the processes generated in the compute nodes.

Excluding a few cases, the data DCRAB collects is taken from the processes which the job has started, not from the entire node. The tool is able to collect the information listed below:

\begin{itemize}
	\item CPU used
	\item Memory usage
	\item Infiniband statistics (of the entire node)
	\item Processes IO statistics
	\item NFS usage (of the entire node)
	\item Disk IO statistics
\end{itemize}

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Installation}

DCRAB has no installation at all, you have to take the lastest version tarball available in Github (currently v2.0) and expand it in a convenient location in your system:

\begin{verbatim}
    tar xzvf ./DCRAB-2.0.tar.gz
\end{verbatim}

This will create a directory called \verb+DCRAB-2.0+ with some subdirectories:

\begin{itemize}
  \item \verb+/auxFiles+ which is used to store the auxiliary files useful for the internal operation mode of the tool as described in \ref{internalReport} section.
  \item \verb+/config+ folder which only contains a folder to store the current version of the tool.
  \item \verb+/docs+ which contains this documentation and the \verb+.tex+ used to generate it.
  \item \verb+/examples+ is used to stored DCRAB's generated report examples of each version since it was created.
  \item \verb+/src+ folder contains the source files of the tool. Inside you will find \verb+dcrab+ script, which is the script that launches DCRAB and a folder called \verb+/script+ that contains other scripts used by the tool to work.
\end{itemize}

Also you will find the \verb+readme.md+ file and the GNU GPL 3.0 license file \verb+COPYING+.

\chapter{Using DCRAB}

\section{Data Collection}
\label{dataCollection}
DCRAB has two operation modes: normal report operation, which may be the mode used by non-admin users, and internal report operation, which is focused to sysadmins. The second operation mode is going to be explained in \ref{internalReport} section, so firstly we will introduce here the normal report operation which will be the commonly used one.

The tool is straightforward to use, you have to add the following lines into your submission script:

\begin{verbatim}
    export DCRAB_PATH=/PATH_TO_DCRAB/
    export PATH=$PATH:$DCRAB_PATH/src
    dcrab start

    ##################################
    #    BLOCK OF CODE TO MONITOR    #
    ##################################

    dcrab finish
\end{verbatim}

Note that the variable \verb+DCRAB_PATH+ must be declared to run DCRAB. You can also make a module with lmod to load the paths in just one line like "module load DCRAB".

DCRAB will start a process in each compute node where the script runs, and will monitor the processes started by it. The script will run as normal, and meanwhile DCRAB will generate a directory report called \verb+dcrab_report_<jobid>+ where \verb+jobid+ is the job number assigned by the scheduler. This reporting directory is generated in the same folder where the job was submitted.

\sloppy Inside this reporting directory, DCRAB will create the reporting file called \verb+dcrab_report.html+, which will be named as "the reporting file" is this document from now on. Generate this file is the main purpose of this monitorization and there you will find statistics and plots to analyze visually the information collected. This report is continuous change (every 10 seconds by default) because the information collected is stored at the time it is taken. So, you could open it with a browser, at the start of the job's execution, and refresh to see what is going on with the job.

One of the goals was to provide a single file to visualize all the data monitored. So, the reporting file is completely modular and you can copy or move it to any location because every plot and image is embedded in the report.

To conclude, say that inside the \verb+dcrab_report_<jobid>+ reporting folder you will find some subdirectories, which normally are not relevant at all for the user because they are generated to guarantee the correct behaviour of the tool. One will be \verb+/data+, which contains for each computing node the files in charge of the management of the processes asociated with the job. Another folder called \verb+/auxFile+ stores the files used for the comunication between compute nodes, and \verb+/log+, which contains the output generated by DCRAB process in each node and DCRAB's main process output (all used for troubleshooting).

\section{Execution Customization}

In DCRAB version 2.0 is not included yet any configuration file to customize the execution, but it is included in the roadmap. However, there are some variables that could be changed inside the code until the configuration file is released:

\begin{itemize}
	\item \texttt{DCRAB\_COLLECT\_TIME}: this variable, inside \verb+src/scripts/dcrab_config.sh+ in \texttt{dcrab\_init\_variables()} function, configures the time between each data collection. By default it is set to 10 seconds.
	\item \texttt{DCRAB\_NFS\_MOUNT\_PATH}: this variable configures the path of the NFS filesystem to be monitored. It is inside \verb+src/scripts/dcrab_node_monitoring_functions.sh+ in \texttt{dcrab\_node\_monitor\_init\_variables()} function. By defaut its value is \verb+/scratch+.
\end{itemize}

\section{Crashed Jobs}
\label{crash}
Update the reporting file continuosly imposed some troubles but it was one of our first goals. There is no much problem for the tool when the job crashes because the report has been generating until that moment, so it brings you such a great trace of what has been occurred and it may contain relevant information about the crash.

The tool exits with code '0' if everything have run normally and exits with code '1' in case of error. To see more information about the crash you can view the logs in /log directory.

In the cases where the reporting directory has been deleted a file called \verb+DCRAB_ERROR_<computeNodeHostname>_<jobid>+ will be generated, per each compute node involved in the calculation, in the same folder as the reporting folder was (where the job was submitted). The \verb+computeNodeHostname+ refers to the hostname of the compute node that throws the error and \verb+jobid+ is the job number assigned by the scheduler to the job.

\section{Requirements}

At this version the tool have a few limitations or requirements for its use:

\begin{itemize}
  \item Support multinode statistics but only for MPI jobs. As is explained in \ref{designAndImplementation} section the execution of the tool differs between the main node and the rest of the nodes. Other nodes that are no the main node will be waiting until a process related to the job is started. In this node may be more processes of the same user in execution but, which of these processes are related to the job that the tool is monitoring? Here is the problem. To know this we need something to compare, something that make us know that the the processes in the main node and the processes in the other nodes are connected. With MPI jobs the command that start the processes have an argument called \verb+control-port+ which one can use to make this comparison and associate the processes of differents nodes in to the same job execution.
  \item Only jobs under PBS scheduler are supported. To be able to monitor correctly the job, DCRAB needs explicity a couple of sentences in the batch script:
  \begin{itemize}
    \item The option \verb+#PBS -l mem=+ must be written explicitly in the submission script for the memory data plot and the memory must be in GB.
    \item The option \verb+#PBS -l nodes=x:ppn=y+ must be written explicitly in the submission script to calculate elapsed and remaining times.
  \end{itemize}
\end{itemize}

\section{Chart Examples}

Below you can find some examples of the charts the tool will generate for the report:

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{img/cpu.png}
\caption{CPU usage}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{img/mem.png}
\caption{Memory usage}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{img/ib.png}
\caption{Infiniband network usage by the node}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{img/io.png}
\caption{I/O against the filesystems}
\end{figure}


\chapter{Design and Implementation}
\label{designAndImplementation}
The main idea of DCRAB was to create a tool easy to use for the users. Notwithstanding that DCRAB is upgrading an HTML file continuosly, the runtime penalty is superfluous.

The continue upgrading of the report conditioned and formed DCRAB's structure. This upgrade is a critical section of the project because all the compute nodes need to write there at the same time, so there is a race condition we had to solve. In early versions we resolved the problem with a lock, to make the writing as an atomic operation, but there was a problem with the delay of parallel filesystems when the reporting file become bigger. The error was when a compute node wrote in the report file. In those writings some data was lost because there is a little delay until the file is upgraded or refreshed with the new information for other nodes. The unique way to solve the problem was to serialize those writings (using a mark in the first line of the report), to be sure one node wrote after the previous node had written.

In its current implementation the tool makes a ssh from the master node to all other nodes. This connection starts a process in background that monitors the processes started by the job and collects information about them (every 10 seconds by default). The tool take advantage of the scheduler to know which processes are related to that job.

\section{Statistics Collected}

DCRAB collects different statistics and information which may be usefull for the user. Here is the complete list of these statistics:

\begin{itemize}
	\item \textbf{CPU used}. The application reports the CPU usage for all the processes started by the job. This data is collected with \verb+ps+ command so it is a snapshot of the process at a concrete time. To have only a view of the main processes in the chart there is a threshold value defined to avoid trivial processes of the user. This information is very useful for applications that use OpenMP.
	\item \textbf{Memory usage}. This value is obtained with the processes' \verb+/proc/<pid>/status+ file where \verb+pid+ is the PID of the process. The tool collect information about Virtual Memory (displayed as VmSize), Resident Memory and Max Resident Memory (displayed as VmRSS). Also is displayed the memory requested by the user for that job in the scheduler and the total memory available in the node.

	If there are more than one node involved in the execution a bigger pie chart is generated to display the amount of memory used for the scheduler (with one node calculation this value is the same as the usage in that node so there is no reason to generate this plot). With this information the users could revise the amount of memory requested into a more real value one to not waste resources, which may also help schedulers' algorithms such as \verb+Backfill+ of Moab.
	\item \textbf{Infiniband statistics (of the entire node)}. There is counted the number of packets and MB of data transfered and received over Infiniband in the entire node (this values can not be collected per processes). This information can be used to improve or revise certain parts of the code, reducing the amount of data transferred over the network, comparing this code section with high network activity levels. This values are taken from the counters available in \verb+/sys/class/infiniband/mlx5_0/ports/1/counters+.
	\item \textbf{Processes IO statistics}. The I/O (Input/Output) made by the processes (regardless of the type of the filesystem). This information can be useful to see if a process is writing more than expected which could be a bottleneck in the program. This data is collected from \verb+/proc/<pid>/io+ file where \verb+pid+ is the PID of the process.
	\item \textbf{NFS usage (of the entire node)}. The I/O (Input/Output) made by the processes on the NFS filesystem determined by \verb+DCRAB_NFS_MOUNT_PATH+ variable. This value, as the Infiniband value, can not be measured by process and must be a collected from the entire node statistics. The information is collected from \verb+mountstats+ command.
	\item \textbf{Disk IO statistics (of the entire node)}. The I/O (Input/Output) made by the processes on the local disks. This data is obtained from \verb+/proc/diskstats+ file so this value is from to the entire node and not only of the current job.
\end{itemize}

\section{Code Structure}

This are the scripts that compose DCRAB. Here does not appear the internal report operation scripts, which are dcrab\_internal\_report\_generation.sh and dcrab\_internal\_report\_functions.sh, because they do nothing in the normal operation mode and will be explained in \ref{internalReportChapter} chapter.

\begin{figure}[H]
\begin{tikzpicture}[
  level 1/.style={sibling distance=55mm},
  edge from parent/.style={->,draw},
  >=latex]

% root of the the initial tree, level 1
\node[root] {dcrab}
% The first level, as children of the initial tree
  child {node[level 2] (c1) {dcrab\_config.sh}}
  child {node[level 2] (c2) {dcrab\_node\_monitor.sh}}
	child {node[level 2, xshift=45pt] (c3) {dcrab\_finalize.sh}};

% The second level, relatively positioned nodes
\node [level 3, below of = c1, xshift=25pt] (c11) {dcrab\_check\_scheduler};
\node [level 3, below of = c11] (c12) {dcrab\_init\_variables};
\node [level 3, below of = c12] (c13) {dcrab\_create\_report\_files};
\node [level 3, below of = c13] (c14) {dcrab\_start\_data\_collection};
\node [level 3, below of = c14] (c15) {dcrab\_save\_environment};

\node [level 3, below of = c2, xshift=40pt, rounded corners=6pt, fill=orange!30, text width=15em] (c21) {dcrab\_node\_monitoring\_functions.sh};
\node [level 4, below of = c21, xshift=20pt] (c211) {dcrab\_node\_monitor\_init\_variables};
\node [level 4, below of = c211] (c212) {dcrab\_wait\_control\_port};
\node [level 4, below of = c212] (c213) {dcrab\_determine\_main\_session};
\node [level 4, below of = c213] (c214) {dcrab\_collect\_data};
\node [level 4, below of = c214, yshift=-35pt, fill=blue!20] (c215) {dcrab\_collect\_mem\_data \\ dcrab\_collect\_ib\_data \\ dcrab\_format\_time \\ dcrab\_collect\_processesIO\_data \\ dcrab\_collect\_nfs\_data \\ dcrab\_collect\_disk\_data \\ dcrab\_collect\_beegfs\_data };

\node [level 3, below of = c215, xshift=-20pt, yshift=-35pt, rounded corners=6pt, fill=orange!30, text width=15em] (c22) {dcrab\_report\_functions.sh};
\node [level 4, below of = c22, xshift=20pt] (c221) {dcrab\_wait\_and\_write};
\node [level 4, below of = c221] (c222) {dcrab\_update\_report};
\node [level 4, below of = c222] (c223) {dcrab\_generate\_html};

\node [level 3, below of = c3, xshift=15pt] (c31) {dcrab\_check\_alive\_main\_node};
\node [level 3, below of = c31] (c32) {dcrab\_check\_exit};
\node [level 3, below of = c32] (c33) {dcrab\_finalize};

\foreach \value in {1,...,5}
  \draw[-] (c1.185) |- (c1\value.west);
\foreach \value in {1,2}
	\draw[-] (c2.185) |- (c2\value.west);
\foreach \value in {1,2,3,4,5}
	\draw[-] (c21.185) |- (c21\value.west);
\foreach \value in {1,2,3}
	\draw[-] (c22.185) |- (c22\value.west);
\foreach \value in {1,2,3}
	\draw[-] (c3.185) |- (c3\value.west);
\end{tikzpicture}
\caption{DCRAB's code structure}
\label{codeTree}
\end{figure}

\begin{figure}[H]

\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=0cm,semithick]
  \tikzstyle{every state}=[draw=none,text=black,node distance=3cm]
  \hspace{-2cm}
\vspace{-0.5cm}
  \node[initial,state,draw,line width = 0.3mm] (A)             {$dcrab$};
  \node[state, fill=blue!20,node distance=5cm] (B) [right of=A] {$Config.$};
  \node[state, rectangle, minimum size=3.5em, line width = 0.3mm, fill=orange!30, cm={cos(45) ,-sin(45) ,sin(45) ,cos(45) ,(0 cm,0 cm)},xshift=2.2cm,yshift=0.8cm]         (Z) [below of=B] {};

  \node[state, fill=green!30,node distance=5cm]         (C) [left of=Z] {$Monitor$};
  \node[state, fill=green!30,node distance=3cm,xshift=-1.5cm,yshift=-1cm]         (D) [below of=C] {$Monitor$};
  \node[state, rectangle,node distance=0cm, minimum size=3.2em, line width = 0.3mm, fill=orange!30,  cm={cos(45) ,-sin(45) ,sin(45) ,cos(45) ,(0 cm,0 cm)},xshift=4.2cm,yshift=4.2cm]         (V) [right of=D] {};
  \node[state, fill=green!30,node distance=3cm,xshift=0.5cm,yshift=-2cm]         (U) [below of=D] {$Monitor$};
  \node[state, fill=green!30,node distance=0cm,xshift=3cm,yshift=-3.5cm]         (E) [below of=U] {$Monitor$};
  \node[state, fill=green!30,node distance=4cm,xshift=3.5cm,yshift=2.5cm]         (F) [below of=E] {$Monitor$};
  \node[state, node distance=0cm, rectangle, minimum size=4.6em, line width = 0.3mm, fill=orange!30,  cm={cos(45) ,-sin(45) ,sin(45) ,cos(45) ,(0 cm,0 cm)},xshift=2cm,yshift=-2cm]         (G) [below of=F] {};
  \node[state, rectangle, minimum size=3.2em, line width = 0.3mm, fill=orange!30,  cm={cos(45) ,-sin(45) ,sin(45) ,cos(45) ,(0 cm,0 cm)},xshift=-5cm,yshift=-8cm]         (H) [above of=G] {};
  \node[state, fill=red!30,yshift=1cm,xshift=13cm]         (W) [below of=H] {$Exit$};
  \node[state, fill=red!30,yshift=-10cm,xshift=6cm]         (T) {$Exit$};
  \node[state, fill=green!30,node distance=5cm]         (I) [right of=Z] {$Monitor$};
  \node[state, fill=green!30,xshift=3cm,yshift=-1cm]         (J) [below of=I] {$Monitor$};
  \node[state, fill=green!30,xshift=-6cm,yshift=3cm]         (K) [below of=J] {$Monitor$};
  \node[state, fill=green!30,xshift=4cm]         (L) [below of=K] {$Monitor$};
  \node[state, rectangle, minimum size=3.2em, line width = 0.3mm, fill=orange!30, cm={cos(45) ,-sin(45) ,sin(45) ,cos(45) ,(0 cm,0 cm)},xshift=4.3cm,yshift=1cm]         (M) [below of=L] {};
	\node[state, node distance=2.5cm,  fill=red!30,xshift=-2cm,yshift=0cm]         (N) [below of=M] {$Finalize$};

  \path (A) edge              node {Executes} (B)
        (B) edge 							node [left] {dcrab\_start\_data\_collection} (Z)
				(Z) edge 							node {} (C)
            edge              node {== 0} (I)
        (C) edge              node {} (D)
        (D) edge              node {} (V)
            edge [loop left]  node {}  (D)
            edge              node {} (U)
        (E) edge              node {dcrab\_update\_report} (F)
        (F) edge              node {dcrab\_check\_exit} (G)
        (G) edge              node [above]{} (H)
            edge              node [below]{Error} (W)
            edge [bend left]  node [left]{!= 0} (U)
        (H) edge [bend left]  node [right] {No} (D)
            %edge [bend right]  node [below] {Yes} (W)
        (I) edge              node {} (J)
        (J) edge              node {} (K)
        (K) edge              node [right] {dcrab\_update\_report} (L)
        (L) edge              node [left]{dcrab\_check\_exit} (M)
        (M) edge [bend right] node {No} (J)
            edge              node {Yes} (N)
        (V) edge [bend left]  node [above] {No} (D)
            edge [bend right] node  {Yes} (T)
        (U) edge              node  {} (E);

% PATH between G and U
%\path [black,bend left,out=-60,in=-150] (H) edge (W);
\draw [->, rounded corners, thick, black, yshift=-20.7cm, xshift=-1.6cm] (0,0) -- (6.4,-1.5) -- (12.4,-1.3);
\node[yshift=-21.8cm,xshift=5cm] (te1) {Yes};

% Modules box
\filldraw[rounded corners=15pt, fill=green!30, draw=black, yshift=-14.5cm, xshift=3cm] (0,0) rectangle (6,3.4);
\node[yshift=-11.5cm, xshift=6cm] (t12)   {dcrab\_node\_monitoring\_functions.sh :};
\node[node distance=0.4cm, xshift=-0.7cm] (t13) [below of=t12] {dcrab\_collect\_mem\_data};
\node[node distance=0.4cm, xshift=-0.2cm] (t14) [below of=t13]  {dcrab\_collect\_ib\_data};
\node[node distance=0.4cm, xshift=1.15cm, yshift=0.05cm] (t15) [below of=t14]  {dcrab\_format\_time(only main node)};
\node[node distance=0.4cm, xshift=-0.38cm, yshift=0.05cm] (t16) [below of=t15]  {dcrab\_collect\_processesIO\_data};
\node[node distance=0.4cm, xshift=-0.67cm, yshift=0.1cm] (t17) [below of=t16]  {dcrab\_collect\_nfs\_data};
\node[node distance=0.4cm, xshift=0.1cm] (t18) [below of=t17]  {dcrab\_collect\_disk\_data};
\node[node distance=0.4cm, xshift=0.15cm] (t19) [below of=t18]  {dcrab\_collect\_beegfs\_data};
\draw[->, dashed,rounded corners, thick, black, yshift=-11cm, xshift=8cm] (0,0) -- (0.4,1.2) -- (-0.5,3);
\draw[<-, dashed, yshift=-14.7cm, xshift=4.5cm]  (-1.6, -0.7) -- (0.1,0.1);

% Config box
\filldraw[rounded corners=15pt, fill=blue!20, draw=black, node distance=0.4cm, yshift=-2cm, xshift=7.5cm] (0,0) rectangle (4.5,2.4);
\node[yshift=0cm, xshift=9cm] (t2)   {dcrab\_config.sh :};
\node[node distance=0.4cm, xshift=0.6cm] (t3) [below of=t2] {dcrab\_init\_variables};
\node[node distance=0.4cm, xshift=0.3cm] (t4) [below of=t3]  {dcrab\_create\_report\_file};
\node[node distance=0.4cm, xshift=0.05cm, yshift=0.05cm] (t5) [below of=t4]  {dcrab\_save\_environment};
\node[node distance=0.4cm, xshift=-0.15cm] (t6) [below of=t5]  {dcrab\_check\_scheduler};
\draw [<-, dashed,rounded corners, thick, black, yshift=-1cm, xshift=6.3cm] (-0.5,0.5) -- (0.2,0) -- (1,0);

% First if statement
\node[node distance=0.4cm, yshift=-2.8cm,xshift=5.0cm] (t40) {Node};
\node[node distance=0.4cm] (t41) [below of=t40] {number};
\node[node distance=0.4cm, yshift=-2.9cm, xshift=2.5cm] (t11) {!=0};

% Monitor first states to second ones
\node[node distance=0.4cm, yshift=-5cm,xshift=2.1cm] (t10) {dcrab\_node\_monitor\_init\_variables};
\node[node distance=0.4cm, xshift=-0.26cm] (t11) [below of=t10] {dcrab\_determine\_main\_session};
\node[node distance=0.4cm, yshift=-5cm,xshift=8.7cm] (t42) {dcrab\_node\_monitor\_init\_variables};
\node[node distance=0.4cm, xshift=-0.275cm,xshift=0.5cm] (t43) [below of=t42] {dcrab\_determine\_main\_session};

% Second state message (!=0 nodes)
\node[yshift=-9.7cm,xshift=0.4cm] (t51)  {MPI process starts};

% Other messages
\node[yshift=-6.5cm,xshift=1.5cm] (t45) {Too much wait};
\node[node distance=0.4cm] (t451) [below of=t45] {dcrab\_check\_alive\_main\_node};
\node[cm={cos(55) ,sin(55) ,-sin(55) ,cos(55) ,(0 cm,0 cm)},yshift=-1.2cm,xshift=-5.5cm] (t44)  {dcrab\_wait\_control\_port};
\node[yshift=-6.9cm,xshift=9.8cm] (t46)  {dcrab\_collect\_data};
\node[cm={cos(50) ,-sin(50) ,sin(50) ,cos(50) ,(0 cm,0 cm)},yshift=-8.3cm,xshift=10.9cm] (t47)  {dcrab\_collect\_data};
\node[yshift=-20.15cm,xshift=2cm] (t51) {dcrab\_check\_alive\_main\_node};
\node[node distance=0.4cm] [below of=t51] (t52)  {(90 seconds of check)};
\node[node distance=0.4cm] [above of=t51] (t53) {== 0};

% All the exit messages
\node[xshift=-0.275cm,yshift=-20cm,xshift=-1.3cm] (t53) {Exit};
\node[xshift=-0.275cm,yshift=-19.5cm,xshift=5.8cm] (t55) {Number};
\node[node distance=0.4cm] [below of=t55] (t551) {of};
\node[node distance=0.4cm] [below of=t551] (t552) {processes};
\node[xshift=-0.275cm,yshift=-14.6cm,xshift=12.9cm] (t56) {Exit};
\node[xshift=-0.275cm,yshift=-7.1cm,xshift=4.7cm] (t57) {Exit};

% Finalize box
\filldraw[rounded corners=15pt, fill=red!20, draw=black, yshift=-20.5cm, xshift=8.1cm] (0,0) rectangle (5,1);
\node[yshift=-19.8cm, xshift=9.6cm] (t21)   {dcrab\_finalize.sh :};
\node[node distance=0.4cm, xshift=1.2cm] (t22) [below of=t21] {dcrab\_stop\_remote\_processes};
\draw [->,dashed, rounded corners, thick, black, yshift=-19.3cm, xshift=10.5cm] (0,0) -- (0.15, 1.35);

% Number of nodes
\node[yshift=0.6cm,xshift=5cm] (t70)  {0};
\node[yshift=-2.5cm,xshift=0cm] (t71)  {1};
\node[yshift=-6.5cm,xshift=-1.5cm] (t72)  {2};
\node[yshift=-11.5cm,xshift=-1.05cm] (t73)  {3};
\node[yshift=-15cm,xshift=2cm] (t74)  {4};
\node[yshift=-16.5cm,xshift=5.5cm] (t75)  {5};
\node[yshift=-9.6cm,xshift=6.0cm] (t76)  {6};
\node[yshift=-21.55cm,xshift=11.45cm] (t76)  {6};
\node[yshift=-2.5cm,xshift=10cm] (t77)  {7};
\node[yshift=-6.5cm,xshift=13cm] (t78)  {8};
\node[yshift=-6.5cm,xshift=7cm] (t79)  {9};
\node[yshift=-9.5cm,xshift=11cm] (t80)  {10};
\node[yshift=-16.4cm,xshift=10.6cm] (t80)  {11};
\end{tikzpicture}
\vspace{-0.9cm}
\caption{DCRAB's state machine}
\label{dcrabCodeScheme}
\end{figure}

Above, in the figure \ref{dcrabCodeScheme}, is presented a bit modificated state machine which presents the states where DCRAB passed through. Each node represents the main steps made by the tool and each edge an operation to change between states. There are boxes attached to some states to point the functions executed on them.

\begin{itemize}
  \item The first node, which is named as \verb+dcrab+, represents the script executed with \verb+dcrab start+ command.
  \item The second node, named as \verb+Config.+ and with the number 0, represents the configuration made by the tool where different functions are executed (attached box in blue color). It starts in each node the data collection but here the execution differs between the main node (where the node number is equal 0, represented as \verb+==0+) and the other nodes that are not the main node (where node number is not equal 0, \verb+!=0+ way).
  \item The sixth nodes were made to represent the stop of DCRAB an will be ommited in below explanations.
  \item \underline{Left part, no main node execution, when the node number is non-zero:}
  \begin{itemize}
    \item The first of the five states that compose the monitoring, which is marked as 1, is the first vertex to analize. These \verb+Monitor+ nodes represent DCRAB processes started in background in each compute nodes. The edge with the next vertex represents the initialization of needed variables to make correctly the data collection and creates the minimal environment to work. Furthermore, it will find the session of the processes created by the job (the tool takes advantage of the scheduler used to identify it).
    \item This second \verb+Monitor+ node, marked with the number 2, is where the tool is ready to collect the data. This vertex is the first that represents tool's execution because the steps done before were just to intializate data structures.

    The first step to explain here is the loop in its left side, which executes the function \texttt{dcrab\_wait\_control\_port()}, and represents the wait that the node must done until a MPI job is started and the execution passes to the next vertex

   On the right part there is drawn a loop with a condition: after a long wait for a MPI job to be started the tool checks if the main node is still executing the job or not (which takes normally about 90 seconds to ensure its state). If it is not still executing the job the tool will stop the execution but in the other case, where the condition is satisfied, the tool will reset its counters and will wait again for the MPI job. This steps are made because a user could insert other no MPI launcher commands inside the 'start' and 'finish' statements of DCRAB that may last for a long time, as huge copies with \verb+cp+ for example.

    \item The next \verb+Monitor+ vertex with number 3 represents the state where the tool knows that a MPI process has been started. It has obtained the session of that MPI processes in the previous step so now it will collect the data related to these processes and move to the next step.
    \item The fourth state represents the data collection. Here all the modules functions are executed and the data is extracted in the way this functions determine. Once this step is done the report is updated and moves down to the next vertex.
    \item This last node, the fifth one, represents the state where the tool has collected and has written the data into the report. Here a few checks are made to ensure the correct behaviour of the tool.

    An important comprobation is made to count the number of MPI processes related to the job that are in execution. If an error occurred in that comprobation the tool will stop.

    The edge marked as \verb+!=0+ is satisfied if there are still MPI processes in execution. It goes back to the third state to make the loop again after a certain sleep (controlled by \verb+DCRAB_COLLECT_TIME+ variable).

    The last case, marked as \verb+==0+, means that all MPI processes have been finished. Here will be done another time the comprobation to check if the main node is still executing the job (normally this takes like 90 seconds) with \texttt{dcrab\_check\_alive\_main\_node()} function. In that comprobation if the main node has already finished the tool will stop but in the other case, the tool will go back to the second step, and will wait until a new MPI job comes.
  \end{itemize}

  \item \underline{Right part, main node execution, when the node number is equal zero:}
  \begin{itemize}
    \item The first vertex, marked with the number 7, is drawn to represent the same steps as the vertex number one, but in this case another data structures will be initialized. This is because the main node must make some other operations in the moment of upgrading the report.
    \item The second node, marked with the 8 number, represents the state where all the initializations have been made. It goes to the next node making the data collection.
    \item The ninth node is were all the data is collected. As the main node, in this step it makes some extra operations inside the modules' functions and also has the resposability of updating the elapsed time inside the report, which is made by the \texttt{dcrab\_format\_time()} function. Finally, it goes towards the next vertex making the report updating.
    \item The node number 10 is drawn to represent the state where the main node has made all its changes in the report. Here it checks if the tool must be stopped or not. If the conditions are satisfied the tool will go to the last node \verb+Finalize+, if not, another loop will be done going back to the eighth state.
    \item The last node, called \verb+Finalize+, is reached when some conditions are satisfied as mentioned. Here DCRAB finishes and is going to kill all DCRAB instances inside the compute nodes (those processes launched in background).
  \end{itemize}
\end{itemize}

\chapter{Creating New Module}

The process to create a new module is straightforward. It could be divided into two main steps, the first one the step where you must make the module to collect wanted data, and the second one modify the html report to display the information collected. The second step is not a must so you can decide not to do and store the collected data into a file. You need to add a few lines in \texttt{dcrab\_node\_monitoring\_functions.sh} for the first part, and other lines into \texttt{dcrab\_report\_functions.sh} script to configure the display.

Below are presented the steps to insert a new module and the best way to name variables and functions in charge of it, however, the names are only a recommendation to preserve the coherence in the code.

\section{Step 1: Data collection}

The first thing to think about, in case you want to plot the collected data, is the type of chart you are going to use. DCRAB is going to upgrade the report file continuously by adding new data to the charts every loop, so you need to know how this data need to be inserted in the report. The charts we used are made with the \href{https://developers.google.com/chart/interactive/docs/reference}{Google Visualization API} so take a look to the documentation to choose one of them.

Once you have choosen one chart type, you have to understand the way you could insert data into them. Normally it consists in generate a string with the correct structure of the new point of the chart to be inserted. We normally store this data string in variables named \verb+DCRAB_MODULENAME_DATA+.

The changes that must be made in \texttt{dcrab\_node\_monitoring\_functions.sh} script are:

\begin{itemize}
  \item In the function \texttt{dcrab\_node\_monitor\_init\_variables()}: the variables needed for your module must be added where the \verb+## NEW MODULE CODE ##+ line is, that is, at the end of other variable declarations. You should use the naming we have used in all the variables of the tool which starts with \verb+DCRAB_+. A variable \verb+DCRAB_NEWMODULENAME_DATA+ should be created, which will be used to insert the data of the new module into the report file.
  \item Create a function, which should name as \texttt{dcrab\_collect\_newModuleName\_data()}, after the last module function defined, where the line \verb+## ADD NEW MODULE'S FUNCTION HERE ##+ is. Collect the data and fill up the variable \verb+DCRAB_NEWMODULENAME_DATA+ must be the purpose of this function. As we have pointed out, remember to generate properly the data on \verb+DCRAB_NEWMODULENAME_DATA+ variable. For example, in most of the cases we fill up the variable with a new point of the charts, which is translated to generate a string with the information of that point using the data collected (you could understand better looking how the data is inserted at the examples in \verb+/examples/normalReport/+ or in the \href{https://developers.google.com/chart/interactive/docs/reference}{Google Visualization API Documentation}).
  \item In the function \texttt{dcrab\_determine\_main\_session()} you have to add at the beginning, where the string \verb+## ADD INITIALIZATION OF NEW MODULE VARIABLE HERE ##+ is, the initialization of the \verb+DCRAB_NEWMODULENAME_DATA+ variable if needed. After that, at the bottom of the same function, add where the string \verb+## ADD THE CALL TO THE NEW FUNCTION HERE ##+ is, the call to the function \texttt{dcrab\_collect\_newModuleName\_data()} created.
  \item Finally, you must repeat the previous step inside the \texttt{dcrab\_collect\_data()} function in the same way.
\end{itemize}

\section{Step 2: Display}

This second step is only needed for display the data into the report, so do not do it if you do not want to visualize the data.

The changes that must be made in \texttt{dcrab\_report\_functions.sh} script are:

\begin{itemize}
  \item We previously store in a file the commands used to make the upgrade in the report and after we execute them at once. The function \texttt{dcrab\_write\_data()} is in charge of this operation and this is where you need to put your own lines: at the bottom of the function, where the string \verb+## NEW MODULE OPERATIONS ##+ is. Be sure to append the command in the file named \verb+DCRAB_COMMAND_FILE+ which will be execute later.
  \item In the function \texttt{dcrab\_generate\_html()} a few modifications need to be make: 1) At the message \verb+## NEW MODULE CODE 1##+ you have to add the data of the chart. 2) Where the message \verb+## NEW MODULE CODE 2 ##+ is you have to add the options of the chart as defined in \href{https://developers.google.com/chart/interactive/docs/reference}{Google Visualization API}. 3) At \verb+## NEW MODULE CODE 3 ##+ you have to create the chart object, call to the draw function and create a listener to be executed when ready event is fired (necessary to the correct drawing of the chart). 4) Add the tab of the new module at \verb+## NEW MODULE CODE 4 ##+. Copy the structure of the above tabs to generate the new one because the names of \verb+<li>+ tag's id, button tag's id and \texttt{tabChanges()} function's arguments must be named as there. 5) Where \verb+## NEW MODULE CODE 5 ##+. is you need to add the chart definition. The required lines to insert correctly the chart are shown below:

  \begin{verbatim}
  printf "%s \n" "<div id=\"processesIOChart\" class=\"chart\" style=\"disp-
  lay:block;\">" >> $DCRAB_HTML
  printf "%s \n" "<div class=\"overflowDivs\">" >> $DCRAB_HTML
  i=1
  while [ $i -le $DCRAB_NNODES ]; do
     printf "%s \n" "<div class=\"inline\">" >> $DCRAB_HTML
     printf "%s \n" "<table><tr><td>" >> $DCRAB_HTML
     printf "%s \n" "<div style=\"width: 1100px;\" class=\"header\">$(echo
     $DCRAB_NODES | cut -d' ' -f $i)</div>" >> $DCRAB_HTML
     printf "%s \n" "</td></tr>" >> $DCRAB_HTML
     printf "%s \n" "<tr><td>" >> $DCRAB_HTML

     #################################
     ## NEW MODULE CHART DEFINITION ##
     #################################

     printf "%s \n" "</td></tr>" >> $DCRAB_HTML
     printf "%s \n" "</table>" >> $DCRAB_HTML
     printf "%s \n" "</div>" >> $DCRAB_HTML
     i=$((i+1))
   done
   printf "%s \n" "</div>" >> $DCRAB_HTML
   printf "%s \n" "</div>" >> $DCRAB_HTML
\end{verbatim}


\end{itemize}


\chapter{Internal Report Operation}
\label{internalReportChapter}
This DCRAB's operation was implemented for sysadmins. DCRAB could monitor some aspects that the scheduler is not able to collect, so this operation mode allows the sysadmins to collect some of the data that only could be catch during the job's execution. Currently, at the 2.0 version, some of the modules added to this operation mode (infiniband and disk modules) are used in the normal mode, so the functions to collect the data are the same.

As the normal operation, it needs a folder to store the necessary files to make the communication between the compute nodes. That file path is set with the variable \verb+DCRAB_REPORT_DIR+, as the normal report operation, but it will point to another path and must be defined. This report directory will have the same structure as the normal operation one that is explained in \ref{dataCollection} section but it will only execute the modules added in this internal operation.

In this operation there is no real-time report generated because the user does not request it, so its not necessary. However, the data monitored is going to be stored in a file to generate the report later. That file, which is set with the \verb+DCRAB_IREPORT_DATA_FILE+ variable, is going to be written only by the main node. The rest of the nodes will store its own data in the folders used to write and the main node will collect their data to write into the file pointed by \verb+DCRAB_IREPORT_DATA_FILE+.

The idea of this mode is to be transparent for the user. If the user decide to not execute DCRAB in his/her job the sysadmin could insert in his/her submission script the lines described in \ref{internalReport} to execute DCRAB in internal operation mode. For this purpose was created the file \texttt{/auxFiles/dcrab\_PBS\_comprobation.sh}.

\section{Activate Internal Report}
\label{internalReport}
The way to activate this operation mode is similar to the normal one:

\ \

\begin{verbatim}
    export DCRAB_PATH=/PATH_TO_DCRAB/
    export PATH=$PATH:$DCRAB_PATH/src
    dcrab istart

    ##################################
    #    BLOCK OF CODE TO MONITOR    #
    ##################################

    dcrab ifinish
\end{verbatim}

Notice that an extra '\verb+i+' must be added to the \verb+start+ and \verb+finish+ commands.

\section{Code Explanation and Customization}

There is not to much to explain in this part, because the core of the internal operation is the same as the normal operation one, however, there are some details that must me pointed. The scripts which compose this operation are:

\begin{itemize}
  \item \texttt{dcrab\_internal\_report\_functions.sh} with two functions: 1) \texttt{dcrab\_internal\_report}- \texttt{\_init\_variables()} to initialize the variables needed for the report and 2) \texttt{dcrab\_write\_internal\_data()} to write into the file that will store the data collected, which is pointed by \verb+DCRAB_IREPORT_DATA_FILE+. This function is going to be executed only by the main node.
  \item \texttt{dcrab\_internal\_report\_generation.sh} which is used to generate the internal report with all the files created per job (with the \verb+DCRAB_IREPORT_DATA_FILE+ variable). This script is adapted to our particular case, so you could create your own one to visualize the data collected with this internal operation mode in the way you want to. However, we will detail the variables you need to change to adapt this script to your own scenario in case you want to use it (in \ref{internalReportCustomization} section).
\end{itemize}

\section{Internal Report Customization}
\label{internalReportCustomization}

There are some variables which may be customize in the internal report:

\begin{itemize}
  \item \texttt{DCRAB\_IREPORT\_DATA\_FILE} inside \texttt{dcrab\_internal\_report\_init\_variables()} function of \verb+dcrab_internal_report_functions.sh+ script. It is used to store the data monitored. It will be only written by the main node.
  \item \texttt{DCRAB\_REPORT\_DIR} inside \texttt{dcrab\_init\_variables()} function in \verb+dcrab_config.sh+ script. In the case of the internal report it is used to configure the path to the reporting file.
\end{itemize}

And here the variables defined in \texttt{dcrab\_internal\_report\_generation.sh} which you could customize to adapt the script to your case and generate the internal report:

\begin{itemize}
  \item \texttt{DCRAB\_IREPORT} which is the path to the internal report file.
  \item \texttt{DCRAB\_IREPORT\_DATA\_DIR} which define the path where the files pointed by \verb+DCRAB_IREPORT_DATA_FILE+ are been generated. For example, if \verb+DCRAB_IREPORT_DATA_FILE+ is defined as \verb+/home/user/dcrab/data/JOBID+ the \verb+DCRAB_IREPORT_DATA_DIR+ variable must be defined as \verb+/home/user/dcrab/data+.
  \item \texttt{DCRAB\_IREPORT\_DATA\_BACKUP\_DIR} define the directory of the data backup. This variable's usage is explained deeper in \ref{intReportAuxScripts} section.
  \item \texttt{DCRAB\_NUMBER\_OF\_BARS} which defined the number of bars to appear in the plot.
  \item \texttt{DCRAB\_NUMBER\_OF\_CHARACTERS} is used to control the width of the progress bar displayed during the execution of the script (it is just an esthetic feature, you do not need to change it).
\end{itemize}

\section{Auxiliary Scripts}
\label{intReportAuxScripts}

There are a few more scripts implemented to make some operations on the internal report:

\begin{itemize}
  \item \texttt{dcrab\_internal\_report\_clean.sh} which recollects all the data generated by all the DCRAB jobs into one file to decrease the number of folders. Furthermore, it makes a tarball of all those files and their report folder and will save it in the directory pointed by \texttt{DCRAB\_IREPORT\_DATA\_BACKUP\_DIR} variable. It also removes the bad files, which may be generated from exited or crashed jobs.
  \item \texttt{dcrab\_PBS\_comprobation.sh} is used to insert into users' jobs script the required lines to execute DCRAB in internal operation mode on PBS scheduler type file. This script modify the file entered as the first argument and prepares it to submmit to the scheduler. It also checks a few scenarios where the user forgets some lines of DCRAB and trys to fix the file. Example of usage:

\begin{verbatim}
./dcrab_PBS_comprobation.sh script.pbs  --> Modifies script.pbs file as below
\end{verbatim}
\end{itemize}

\pagebreak

\begin{multicols}{2}
\begin{verbatim}
BEFORE

#!/bin/bash
#PBS -q parallel
#PBS -l nodes=1:ppn=24
#PBS -l mem=150gb
#PBS -l cput=1000:00:00
#PBS -N daniTestJob

module load QuantumESPRESSO
cd $PBS_O_WORKDIR

mpirun -np 24 pw.x < ausurf.in >& OUT

\end{verbatim}

\columnbreak

\begin{verbatim}

AFTER

#!/bin/bash
#PBS -q parallel
#PBS -l nodes=1:ppn=24
#PBS -l mem=150gb
#PBS -l cput=1000:00:00
#PBS -N daniTestJob
export DCRAB_PATH=/home/user/dcrab/software
export PATH=$PATH:$DCRAB_PATH/src
dcrab istart

module load QuantumESPRESSO
cd $PBS_O_WORKDIR

mpirun -np 24 pw.x < ausurf.in >& OUT

dcrab ifinish
\end{verbatim}
\end{multicols}

\chapter{Script Examples}

\begin{verbatim}
#!/bin/bash
#PBS -q parallel
#PBS -l nodes=2:ppn=24
#PBS -l mem=180gb
#PBS -l cput=760:00:00
#PBS -N Heusler_AgMnSn_64pts

export DCRAB_PATH=/scratch/user/DCRAB
export PATH=$PATH:$DCRAB_PATH/src
dcrab start

cd $PBS_O_WORKDIR

module load SIESTA/4.1-b3-foss-2017b

export NPROCS=`wc -l < $PBS_NODEFILE`

mpirun -np $NPROCS --map-by ppr:24:node siesta  AgMnSn.fdf >& OUTPUT

sleep 200

mpirun -np $NPROCS --map-by ppr:24:node siesta  AgMnSn.fdf >& OUTPUT2

sleep 200

mpirun -np $NPROCS --map-by ppr:24:node siesta  AgMnSn.fdf >& OUTPUT3

sleep 200

dcrab finish
\end{verbatim}

\pagebreak

\begin{verbatim}
#!/bin/bash
#PBS -q parallel
#PBS -l nodes=1:ppn=24:mediumsize
#PBS -l mem=192gb
#PBS -l cput=1000:00:00
#PBS -N JOB_NAME

export DCRAB_PATH=/scratch/user/DCRAB
export PATH=$PATH:$DCRAB_PATH/src
dcrab start

export LSCRATCH_DIR=/lscratch/$USER/jobs/$PBS_JOBID

mkdir -p $LSCRATCH_DIR
cd $PBS_O_WORKDIR
cp -r * $LSCRATCH_DIR
cd $LSCRATCH_DIR

module load program/version

export NPROCS=`wc -l < $PBS_NODEFILE`

mpirun -np $NPROCS program >& OUTPUT_FILE

export RESULTS_DIR=$PBS_O_WORKDIR/RESULTS
mkdir -p $RESULTS_DIR
cp -r * $RESULTS_DIR
rm -rf $LSCRATCH_DIR

dcrab finish
\end{verbatim}

\end{document}
